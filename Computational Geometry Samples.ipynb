{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Geometry Samples in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: 'Discrete and Computational Geometry' (2011) Devadoss and O'Rourke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'triangle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-09f212f2be05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcircumcircle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtriangle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'triangle'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import itertools\n",
    "import circumcircle\n",
    "import triangle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import scipy.optimize\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "%matplotlib inline\n",
    "import math\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import cPickle as pickle\n",
    "import shapefile #Python pyshp library\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib import colors\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction: What is Computational Geometry? Why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: the study of computer algorithms that perform geometric operations. \n",
    "    \n",
    "**Applications**:\n",
    " - computer graphics\n",
    " - computer-aided design / drafting (CAD)\n",
    " - robotic motion planning / collision avoidance\n",
    " - geographic information systems (GIS) / search and rescue, etc.\n",
    " - computer vision (3D reconstruction)\n",
    " - computational biochemistry / virology\n",
    " - epidemiology (water source contamination)\n",
    " - ecology (species habitat estimates based on sightings)\n",
    " - integrated circuit design\n",
    " - enconomical construction of physical networks\n",
    " - cooking ingredient logistics (success polygons)\n",
    " \n",
    " A \"young field,\" with modern computational geometry starting in ~ the 1970s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Definition: \n",
    "\"A polygon is the closed region of the plane bounded by a finite collection of line segments forming a closed curve that does not intersect itself.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot an example of a polygon and an object that fails to be a polygon\n",
    "\n",
    "\n",
    "fig_2_1 = matplotlib.pyplot.figure()\n",
    "\n",
    "polygon_vertices = np.array([[0,2], #top left\n",
    "                             [2,2], #top right\n",
    "                             [2,0], #bottom right\n",
    "                             [0,0]]) #bottom left\n",
    "\n",
    "self_intersection_vertices = np.array([[0,2], #top left\n",
    "                                       [2,2], #top right\n",
    "                                       [0,0], #bottom left\n",
    "                                       [2,0]]) #bottom right\n",
    "\n",
    "ax = fig_2_1.add_subplot(121)\n",
    "ax.scatter(polygon_vertices[...,0], polygon_vertices[...,1], color='black', s=200, label = 'vertices')\n",
    "polygon = Polygon(polygon_vertices, alpha = 0.5)\n",
    "ax.add_patch(polygon)\n",
    "ax.set_title('A Polygon', fontsize=18)\n",
    "\n",
    "ax2 = fig_2_1.add_subplot(122)\n",
    "ax2.scatter(self_intersection_vertices[...,0], self_intersection_vertices[...,1], color='black', s=200, label = 'vertices')\n",
    "polygon = Polygon(self_intersection_vertices, alpha = 0.5)\n",
    "ax2.add_patch(polygon)\n",
    "ax2.set_title('Self-Intersection = Not a Polygon', fontsize=18)\n",
    "\n",
    "for axis in [ax,ax2]:\n",
    "    axis.set_xlabel('x', fontsize = 16)\n",
    "    axis.set_ylabel('y', fontsize = 16)\n",
    "\n",
    "#some text labels for the polygon case\n",
    "ax.text(0.85,2.1,'Edge', fontsize = 16)\n",
    "ax.text(0.85,-0.2,'Edge', fontsize = 16)\n",
    "ax.text(-0.25,1.0,'Edge', fontsize = 16, rotation=90)\n",
    "ax.text(2.1,1.0,'Edge', fontsize = 16, rotation=90)\n",
    "ax.text(-0.4,2.3,'Vertex', fontsize = 16, rotation=-45)\n",
    "ax.text(2.0,2.3,'Vertex', fontsize = 16, rotation=45)\n",
    "ax.text(-0.4,-0.1,'Vertex', fontsize = 16, rotation=45)\n",
    "ax.text(2.0,-0.1,'Vertex', fontsize = 16, rotation=-45)\n",
    "\n",
    "fig_2_1.set_size_inches(17,8.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Every Polygon Has A Triangulation:\n",
    "\n",
    "Some useful definitions:\n",
    "    \n",
    "1. **Diagonal**: a line segment connecting two vertices of P and lying in the interior of P, not touching $\\partial$P except at its endpoints\n",
    "2. **Triangulation**: a decomposition of P into triangles by a maximal set of noncrossing diagonals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(y_value_p1 = widgets.FloatSlider(min=-1,max=2.1,step=0.1,value=-1),\n",
    "          y_value_p2 = widgets.FloatSlider(min=-1,max=2.1,step=0.1,value=-1),\n",
    "          new_diagonal_p2 = False)\n",
    "def polygon_sweep(y_value_p1, y_value_p2, new_diagonal_p2):\n",
    "    fig_2_2 = matplotlib.pyplot.figure()\n",
    "    fig_2_2.set_size_inches(17,8.5)\n",
    "\n",
    "    polygon_1 = np.array([[0,2],#top\n",
    "                          [-1,1],#left\n",
    "                          [0,-1], #bottom\n",
    "                          [1,1]])#right\n",
    "\n",
    "    polygon_2 = np.array([[0,0.7],#top\n",
    "                          [-1,2],#left\n",
    "                          [0,-1],#bottom\n",
    "                          [1,2]])#right\n",
    "\n",
    "    ax1 = fig_2_2.add_subplot(121)\n",
    "    p1 = Polygon(polygon_1, color='blue', alpha = 0.2)\n",
    "    ax1.add_patch(p1)\n",
    "    ax1.scatter(polygon_1[...,0], polygon_1[...,1], s=80)\n",
    "    ax2 = fig_2_2.add_subplot(122)\n",
    "    p2 = Polygon(polygon_2, color='blue', alpha = 0.2)\n",
    "    ax2.add_patch(p2)\n",
    "    ax2.scatter(polygon_2[...,0], polygon_2[...,1], s=80)\n",
    "\n",
    "    for axis in [ax1,ax2]:\n",
    "        axis.set_xlim(-1.2,1.2)\n",
    "        axis.set_ylim(-1.1,2.1)\n",
    "    ax1.axhline(y=y_value_p1, lw=4, color = 'black')\n",
    "    ax2.axhline(y=y_value_p2, lw=4, color = 'black')\n",
    "    if new_diagonal_p2:\n",
    "        ax2.axvline(x=0,ymin=0.03,ymax=0.55,color='green',lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Every triangulation of a polygon with n vertices has n - 2 triangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we will deal with triangulations in greater detail later, here we will use a specific type of triangulation (a **constrained** triangulation) available in the award-winning **Triangle** library to see a demonstration of the above property on some interesting polygons. The Python bindings were written by Dzhelil Rufat--the original **Triangle** library was written by Jonathan Shewchuk (Prof. at UC Berkeley)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = shapefile.Reader(\"shapefiles/cb_2015_us_state_20m.shp\") #a pain to figure out where / how to download these from Government websites\n",
    "shapeRecs = sf.shapeRecords()\n",
    "for shapeRec in shapeRecs:\n",
    "    if 'Oregon' in shapeRec.record:\n",
    "        Oregon_vertices = np.array(shapeRec.shape.points)\n",
    "        \n",
    "#filter out roughly co-linear points for the purpose of the Triangle library (otherwise get segfault problems)\n",
    "rows_to_keep = []\n",
    "index = 0\n",
    "while index < Oregon_vertices.shape[0] - 1:\n",
    "    current_x_coord = Oregon_vertices[index,0]\n",
    "    current_y_coord = Oregon_vertices[index,1]\n",
    "    next_x_coord = Oregon_vertices[index + 1,0]\n",
    "    next_y_coord = Oregon_vertices[index + 1,1]\n",
    "    if abs(current_x_coord - next_x_coord) < 0.001 or abs(current_y_coord - next_y_coord) < 0.001:\n",
    "        index += 1\n",
    "        continue\n",
    "    else:\n",
    "        rows_to_keep.append(index)\n",
    "        index += 1\n",
    "        \n",
    "Oregon_vertices = Oregon_vertices[rows_to_keep]\n",
    "Oregon_vertices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regular_polygon_vertices(r, n_vertices):\n",
    "    iteration_values = np.arange(n_vertices)\n",
    "    angles = 2 * math.pi * iteration_values / float(n_vertices)\n",
    "    x_coords = r * np.cos(angles)\n",
    "    y_coords = r * np.sin(angles)\n",
    "    polygon_coords = np.stack((x_coords, y_coords), axis=-1)\n",
    "    return polygon_coords\n",
    "\n",
    "#generate the 65537-gon, which Hermes worked on for 10 years in a 200-page manuscript\n",
    "polygon_Hermes = generate_regular_polygon_vertices(1.0, 65537)\n",
    "polygon_Hermes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot the polygons of interest with interactive widget(s) for triangulation, etc.\n",
    "\n",
    "@interact(triangulate_Oregon= False,\n",
    "          triangule_Hermes = False)\n",
    "def triangulation_demo(triangulate_Oregon=False, triangulate_Hermes=False):\n",
    "    fig_2_3 = plt.figure()\n",
    "    ax1 = fig_2_3.add_subplot(121)\n",
    "    ax1.scatter(Oregon_vertices[...,0], Oregon_vertices[...,1])\n",
    "    p_Oregon = Polygon(Oregon_vertices, color='green', alpha = 0.4)\n",
    "    ax1.add_patch(p_Oregon)\n",
    "    ax1.set_title('Oregon', fontsize=18)\n",
    "    ax2 = fig_2_3.add_subplot(122)\n",
    "    ax2.scatter(polygon_Hermes[...,0], polygon_Hermes[...,1])\n",
    "    ax2.set_title('65537-gon', fontsize=18)\n",
    "    fig_2_3.set_size_inches(17,8.5)\n",
    "    \n",
    "    if triangulate_Oregon:\n",
    "        #need vertex indices for all edges of the polygon\n",
    "        segment_start_indices = np.arange(Oregon_vertices.shape[0])\n",
    "        segment_end_indices = segment_start_indices + 1\n",
    "        segment_end_indices[-1] = 0\n",
    "        segment_indices = np.array(zip(segment_start_indices, segment_end_indices))\n",
    "        print 'Oregon_vertices.shape:', Oregon_vertices.shape\n",
    "        Oregon_vertex_dict = dict(vertices = Oregon_vertices, segments = segment_indices)\n",
    "        tri = triangle.triangulate(Oregon_vertex_dict, 'p') #'p' for triangulation of planar graph\n",
    "        print 'Oregon num triangles:', tri['triangles'].shape\n",
    "        simplex_coords = Oregon_vertices[tri['triangles']]\n",
    "        triangles = PolyCollection((simplex_coords), alpha = 0.3)\n",
    "        ax1.add_collection(triangles)\n",
    "        \n",
    "    if triangulate_Hermes:\n",
    "        segment_start_indices = np.arange(polygon_Hermes.shape[0])\n",
    "        segment_end_indices = segment_start_indices + 1\n",
    "        segment_end_indices[-1] = 0\n",
    "        segment_indices = np.array(zip(segment_start_indices, segment_end_indices))\n",
    "        Hermes_vertex_dict = dict(vertices = polygon_Hermes, segments = segment_indices)\n",
    "        tri = triangle.triangulate(Hermes_vertex_dict, 'p') #'p' for triangulation of planar graph\n",
    "        print '65537-gon num triangles:', tri['triangles'].shape\n",
    "        simplex_coords = polygon_Hermes[tri['triangles']]\n",
    "        triangles = PolyCollection((simplex_coords), alpha = 0.3)\n",
    "        ax2.add_collection(triangles)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.4 The Catalan Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convex Polygon**: every pair of nonadjacent vertices determines a diagonal\n",
    "\n",
    "**Catalan Number**: the number of triangulations of a convex polygon with n + 2 vertices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$C_n = \\frac{(2n)!}{(n+1)!n!}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalan_number(num_vertices):\n",
    "    n = num_vertices - 2\n",
    "    Catalan = math.factorial(2 * n) / (math.factorial(n + 1) * math.factorial(n))\n",
    "    return Catalan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many triangulations are possible for the 65537-gon?\n",
    "triangulation_count_Hermes = catalan_number(65537)\n",
    "triangulation_count_Hermes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok, that's a lot of possible triangulations! For a square there should only be two possibilities:\n",
    "triangulation_count_square = catalan_number(4)\n",
    "triangulation_count_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that looks sensible (though the derivation is non-trivial for me!) and could be a useful i.e., unit test in some circumstances. It is not so simple to deal with the possible triangulations of non-convex polygons, but convex polygons have the most triangulations, so the total permutations are always between 1 and the catalan number--for *any* polygon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 The Art Gallery Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem posed by Victor Klee in 1973: what is the fewest number of (stationary) guards (capable of 360 degree vision) placed anywhere inside a polygon that would have sufficient line of sight coverage to cover the entire polygon interior?\n",
    "\n",
    "Many versions of the posed problem are NP-hard! It has been firmly established that floor($\\frac{n}{3}$) guards  are always sufficient and sometimes necessary to guard a polygon with n vertices. Protecting the exterior (the *Fortress Problem*) is more difficult--ceiling($\\frac{n}{2}$) guards are always sufficient and sometimes necessary to cover the exterior of any given polygon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A Pentagon\n",
    "max_guards_pentagon = math.floor(5./3.)\n",
    "max_fortress_pentagon = math.ceil(5./2.)\n",
    "max_guards_pentagon, max_fortress_pentagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pentagon_coords = np.array([[0,0],#bottom left\n",
    "                            [0,0.3],#top left\n",
    "                            [1.0,0.5],#top\n",
    "                            [2.0,0.2],#right\n",
    "                            [1.7,0.0]]) #bottom right\n",
    "fig_2_5 = plt.figure()\n",
    "ax = fig_2_5.add_subplot(121)\n",
    "p = Polygon(pentagon_coords, color='orange', alpha = 0.3)\n",
    "ax.text(1.0,0.2,'G1')\n",
    "closed_polygon_coords = np.zeros((6,2))\n",
    "closed_polygon_coords[:-1,...] = pentagon_coords\n",
    "closed_polygon_coords[-1, ...] = pentagon_coords[0,...]\n",
    "ax.add_patch(p)\n",
    "ax.set_title('Single Guard Covers Pentagon Interior')\n",
    "ax2 = fig_2_5.add_subplot(122)\n",
    "\n",
    "for axis in [ax,ax2]:\n",
    "    axis.set_xlim(-0.2,2.1)\n",
    "    axis.set_ylim(-1,1.3)\n",
    "    axis.plot(closed_polygon_coords[...,0], closed_polygon_coords[...,1], c = 'black')\n",
    "    axis.scatter(pentagon_coords[...,0], pentagon_coords[...,1], c = 'black', s=80)\n",
    "\n",
    "ax2.set_title('Three Guards Cover Pentagon Exterior')\n",
    "ax2.text(-0.17,0.4, 'G1')\n",
    "ax2.text(1.75,-0.2, 'G2')\n",
    "ax2.text(1.6,0.5, 'G3')\n",
    "\n",
    "#draw the lines of sight for the the guards using triangles\n",
    "g1_t1 = Polygon(np.concatenate((np.array([[-0.15,0.38]]),pentagon_coords[0:2])), color='blue', alpha = 0.3)\n",
    "g1_t2 = Polygon(np.concatenate((np.array([[-0.15,0.38]]),pentagon_coords[1:3])), color='blue', alpha = 0.3)\n",
    "ax2.add_patch(g1_t1)\n",
    "ax2.add_patch(g1_t2)\n",
    "g2_t1 = Polygon(np.concatenate((np.array([[1.75,-0.2]]),np.array([closed_polygon_coords[-2]]),np.array([closed_polygon_coords[0]]))), color='violet', alpha = 0.3)\n",
    "g2_t2 = Polygon(np.concatenate((np.array([[1.75,-0.2]]),np.array([closed_polygon_coords[-2]]),np.array([closed_polygon_coords[-3]]))), color='violet', alpha = 0.3)\n",
    "ax2.add_patch(g2_t1)\n",
    "ax2.add_patch(g2_t2)\n",
    "g3_t1 = Polygon(np.concatenate((np.array([[1.6,0.5]]),np.array([closed_polygon_coords[-3]]),np.array([closed_polygon_coords[-4]]))), color='brown', alpha = 0.3)\n",
    "ax2.add_patch(g3_t1)\n",
    "\n",
    "fig_2_5.set_size_inches(17, 8.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above case the upper bounds for guarding the interior and exterior of the pentagon also appear to be the optimal solutions. It is useful to have these boundaries to assess i.e., if the number of guards you have suggested for a given polygon is within the theoretical upper limit.\n",
    "\n",
    "However, given an arbitrary polygon and a suggested number of guards, determining if said polygon can be covered by that number of guards is generally NP-hard. As a simple example of the dissociation of the number of sufficient guards (no more than this number are ever required for a given polygon of n vertices) and the minimum number required to cover a given polygon, let's consider hexagons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hexagon Art Gallery\n",
    "max_guards_hexagon = math.floor(6./3.)\n",
    "max_guards_hexagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demonstrate hexagons that require 1 or 2 guards with triangulation overlays\n",
    "@interact(Fisk1=False,\n",
    "          Fisk2=False)\n",
    "def hexagon_demonstration(Fisk1=False,Fisk2=False):\n",
    "    hexagon_1 = np.array([[0,1],#top left\n",
    "                         [1,2],#top\n",
    "                         [2,1],#top right\n",
    "                         [2,0],#bottom right\n",
    "                         [1,-1],#bottom\n",
    "                         [0,0]])#bottom left\n",
    "    fig_hex = plt.figure()\n",
    "    fig_hex.set_size_inches(17,8.5)\n",
    "    ax1 = fig_hex.add_subplot(121)\n",
    "    ax1.scatter(hexagon_1[...,0], hexagon_1[...,1],c='black',s=80)\n",
    "    closed_polygon_coords = np.zeros((7,2))\n",
    "    closed_polygon_coords[:-1,...] = hexagon_1\n",
    "    closed_polygon_coords[-1, ...] = hexagon_1[0,...]\n",
    "    ax1.plot(closed_polygon_coords[...,0], closed_polygon_coords[...,1], c='black')\n",
    "    ax1.set_title('Single Guard Covers Hexagon Interior')\n",
    "\n",
    "    hexagon_2 = np.array([[0,0],#bottom left\n",
    "                          [0.25,1],#top left\n",
    "                          [0.5,0.5], #left\n",
    "                          [1.5,0.5], #right\n",
    "                          [1.75,1],#top right\n",
    "                          [2,0]]) #bottom right\n",
    "    \n",
    "    ax2 = fig_hex.add_subplot(122)\n",
    "    ax2.scatter(hexagon_2[...,0], hexagon_2[...,1],c='black',s=80)\n",
    "    ax2.set_title('Two Guards Needed to Cover Interior of Hexagon')\n",
    "    closed_polygon_coords = np.zeros((7,2))\n",
    "    closed_polygon_coords[:-1,...] = hexagon_2\n",
    "    closed_polygon_coords[-1, ...] = hexagon_2[0,...]\n",
    "    ax2.plot(closed_polygon_coords[...,0], closed_polygon_coords[...,1], c='black')\n",
    "    \n",
    "    if Fisk1:\n",
    "        #constrained triangulation of the first hexagon:\n",
    "        segment_start_indices = np.arange(6)\n",
    "        segment_end_indices = segment_start_indices + 1\n",
    "        segment_end_indices[-1] = 0\n",
    "        segment_indices = np.array(zip(segment_start_indices, segment_end_indices))\n",
    "        hexagon_1_vertex_dict = dict(vertices = hexagon_1, segments = segment_indices)\n",
    "        tri = triangle.triangulate(hexagon_1_vertex_dict, 'p') \n",
    "        simplex_coords = hexagon_1[tri['triangles']]\n",
    "        triangles = PolyCollection((simplex_coords), alpha = 0.1)\n",
    "        ax1.add_collection(triangles)\n",
    "        #use colour scheme from Steve Fisk's proof of the floor(n/3) limit\n",
    "        colours = ['red','blue','green','blue','red','green'] \n",
    "        for vertex in hexagon_1:\n",
    "            ax1.scatter(vertex[0], vertex[1], color=colours.pop(0), s=81)\n",
    "\n",
    "    if Fisk2:\n",
    "        #constrained triangulation of the second hexagon:\n",
    "        segment_start_indices = np.arange(6)\n",
    "        segment_end_indices = segment_start_indices + 1\n",
    "        segment_end_indices[-1] = 0\n",
    "        segment_indices = np.array(zip(segment_start_indices, segment_end_indices))\n",
    "        hexagon_2_vertex_dict = dict(vertices = hexagon_2, segments = segment_indices)\n",
    "        tri = triangle.triangulate(hexagon_2_vertex_dict, 'p') \n",
    "        simplex_coords = hexagon_2[tri['triangles']]\n",
    "        triangles = PolyCollection((simplex_coords), alpha = 0.1)\n",
    "        ax2.add_collection(triangles)\n",
    "        #use colour scheme from Steve Fisk's proof of the floor(n/3) limit\n",
    "        colours = ['red','green','blue','red','blue','green'] \n",
    "        for vertex in hexagon_2:\n",
    "            ax2.scatter(vertex[0], vertex[1], color=colours.pop(0), s=81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum count of the colours is the sufficient number of guards to guarantee internal coverage, but less guards can be used in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the 3D case is more complicated because not all polyhedra can be tetrahedralized. Indeed, even placing a guard at every single vertex of the polyhedron does not necessarily guarantee full coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3) Convex Hulls (and transition to point sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Convexity, Convex Hulls and General Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convex Regions**: a region is convex if any two points of the region are visible to one another within the region. The **convex hull** is the smallest convex region containing the point set *S*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convex Hull by Example -- Back to Kindergarden Geoboards**\n",
    "![Geoboard](images/geoboard.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate it yourself with the incredibly-useful `scipy.spatial` library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a simple example of the convex hull for a random set of points in the plane\n",
    "random_2D_array = np.random.random_sample((35,2))\n",
    "hull = scipy.spatial.ConvexHull(random_2D_array)\n",
    "sample_hull_plot = scipy.spatial.convex_hull_plot_2d(hull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites: **General Position**\n",
    "\n",
    "A set of points (or other geometric objects) are said to be in **general position** if they avoid troublesome configurations, known as *degenerate* situations. The precise definition of **general position** varies depending on the algorithm. A point set is always in general position if the n points are chosen randomly, but this is (of course) not the case with real world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce an example of a degenerate point set:\n",
    "fig_degenerate = plt.figure()\n",
    "degenerate_vertices = np.array([[0,0],\n",
    "                                [1,0],\n",
    "                                [2,0],\n",
    "                                [3,0],\n",
    "                                [3,1],\n",
    "                                [2,1],\n",
    "                                [1,1],\n",
    "                                [1.5,0.6],\n",
    "                                [0.4,0.3]])\n",
    "ax = fig_degenerate.add_subplot(111)\n",
    "ax.scatter(degenerate_vertices[...,0], degenerate_vertices[...,1], c='k', s=70)\n",
    "ax.set_title('A degenerate point set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try calculating the convex hull of the above point set\n",
    "hull = scipy.spatial.ConvexHull(degenerate_vertices, qhull_options='Qc')\n",
    "plot = scipy.spatial.convex_hull_plot_2d(hull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull.coplanar #the above computation is possible because Qhull is able to ignore a subset of the pathological input points (their indices and neighbour indices are only computed with the additional 'Qc' option sent to Qhull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the algorithm actually handles the potentially pathological collinear data, but it is important to note that this kind of data could typically cause issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Practical Algorithm Time & Space Complexities\n",
    "\n",
    "Convex Hull algorithms are fundamental to computational geometry and it is useful to have a working knowledge of the terminology used to describe their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexity analysis captures the speed of an algorithm as a function of data input size using *Big-Oh* notation.\n",
    "\n",
    "For a specific algorithm and an input of size $n$, the running time is captured as $O(f(n))$, and $cf(n)$ is the upper bound on the running time of the algorithm, where $c>0$ is a constant. The upper bound means that we typically ignore lower values of $n$ and focus on the asymptotic 'worst-case' scenarios.\n",
    "\n",
    "Selected Examples:\n",
    "\n",
    "| big-Oh notation | name | Example | \n",
    "|-----------------|-------------|---|\n",
    "|$O(1)$ | Constant | Adding two numbers\n",
    "|$O(n \\textrm{ log } n)$ | loglinear | Sorting a list\n",
    "|$O(n^2)$ | Quadratic | Incremental convex hull algorithm\n",
    "|$O(n^k)$ | Polynomial | Robot Arm Motion Planning\n",
    "|$O(c^n)$ | Exponential | Some Brute Force Algorithms\n",
    "\n",
    "\n",
    "We focus on **time complexity**, but there are also cases where memory usage (**space complexity**) is critical for an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Determine the time complexity of the `ConvexHull` algorithm used by `scipy.spatial` (which is actually just a wrapper for the popular `qhull` package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use an empirical approach, although an expert could study the algorithm / source code and identify the 'rate-limiting' step based on the type of operations performed\n",
    "\n",
    "def linear(n, m, c):\n",
    "    return m * n + c\n",
    "\n",
    "def loglinear(n, m, c):\n",
    "    return m * (n * np.log(n)) + c\n",
    "\n",
    "def quadratic(n, m, c):\n",
    "    return m * (n ** 2) + c\n",
    "\n",
    "points_list = [1000,20000,30000,50000,70000,100000,200000,300000,500000,700000,900000,1000000]\n",
    "list_times = []\n",
    "\n",
    "for num_points in points_list:\n",
    "    random_2D_points = np.random.random_sample((num_points,2))\n",
    "    start_time = time.time()\n",
    "    hull = scipy.spatial.ConvexHull(random_2D_points)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    list_times.append(elapsed_time)\n",
    "    print 'benchmarked', num_points, 'points in:', elapsed_time, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = scipy.optimize.curve_fit(linear, points_list, list_times)\n",
    "linear_y_data = linear(np.array(points_list), popt[0], popt[1])\n",
    "popt, pcov = scipy.optimize.curve_fit(loglinear, points_list, list_times)\n",
    "loglinear_y_data = loglinear(np.array(points_list), popt[0], popt[1])\n",
    "popt, pcov = scipy.optimize.curve_fit(quadratic, points_list, list_times)\n",
    "quadratic_y_data = quadratic(np.array(points_list), popt[0], popt[1])\n",
    "\n",
    "fig_bench_hull = plt.figure()\n",
    "ax = fig_bench_hull.add_subplot(111)\n",
    "ax.scatter(points_list, list_times, c='k', label='original data', s = 80)\n",
    "ax.plot(points_list, list_times, c='k', label='original data')\n",
    "\n",
    "ax.plot(points_list, linear_y_data, c = 'blue', lw=7,alpha = 0.3, label = 'linear')\n",
    "ax.plot(points_list, loglinear_y_data, c = 'red', lw=7,alpha = 0.3, label = 'loglinear')\n",
    "ax.plot(points_list, quadratic_y_data, c = 'green', lw=7,alpha = 0.3, label = 'quadratic')\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_title('Crude Time Complexity Assessment\\nFor Qhull 2D Convex Hull')\n",
    "ax.set_xlim(-50,1.2e+6)\n",
    "ax.set_ylim(-0.02,0.20)\n",
    "ax.set_xlabel('# Points',fontsize=16)\n",
    "ax.set_ylabel('Time (s)', fontsize=16)\n",
    "fig_bench_hull.set_size_inches(8,8)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qhull implements the Quickhull algorithm for convex hull [Barber et al. '96]. It has output-sensitive performance that can slightly improve on loglinear in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above Qhull algorithm is highly specialized / optimized and works well across several dimensions, a more straightforward summary of general Convex Hull algorithm performance is shown below:\n",
    "\n",
    "\n",
    "Paradigm | 2D Complexity | 3D Complexity | Notes\n",
    "---------|---------------|---------------|-------\n",
    "Incremental | $O(n^2)$ | $O(n^2)$| often implemented because of conceptual simplicity\n",
    "Gift-wrapping | $O(nh)$ | $O(nf)$| \n",
    "Graham scan | $O(n\\:{\\log}\\:n)$ | N/A |\n",
    "divide-and-conquer (recursion) | $O(n\\:{\\log}\\:n)$ | $O(n\\:{\\log}\\:n)$| 4D and up: $\\Omega(n^{d/2})$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Can the Python community do better than `scipy.spatial.ConvexHull`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NO**, not from an algorithmic standpoint, because loglinear performance is the lower bound on sorting operations and we can reduce the convex hull problem (in the simplest case) to a sorting problem for a parabola:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(12)\n",
    "y = x ** 2\n",
    "fig_hull = plt.figure()\n",
    "ax = fig_hull.add_subplot(111)\n",
    "ax.scatter(x,y,s=80,c ='k')\n",
    "closed_parabola = np.zeros((x.shape[0] + 1,2))\n",
    "closed_parabola[:-1,0] = x\n",
    "closed_parabola[:-1,1] = y\n",
    "closed_parabola[:-1] = np.array(x[0],y[0])\n",
    "parabola = np.array(zip(x,y))\n",
    "p = Polygon(parabola, alpha = 0.2)\n",
    "ax.add_patch(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that, even if we didn't care about connectivity (i.e., only wanted the hull points without their order), the fastest possible performance is still loglinear. This was discovered relatively recently (1985) by Franco Preparata and Michael Shamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.4 Practical Examples with `scipy.spatial.ConvexHull`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Let's say you have a startup that built a long-distance robot that you'd like to send along land from the far West of Oregon to its Eastern Border. However, a sufficient number of Oregon residents have objected to this project such that a straight line through the State will not be possible. Instead, you decide to treat the entire area of Oregon as hazardous for the robot, planning to travel on the borders (or in the more permissive neibhouring States) only. Assuming flat terrain, find the minimum total distance that may be traveled by the robot from the Westernmost point of Oregon to its Easternmost point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the indices of the West / East limit points (which also fall on the convex hull, by definition):\n",
    "x_min_index = np.argmin(Oregon_vertices[...,0])\n",
    "x_max_index = np.argmax(Oregon_vertices[...,0])\n",
    "x_min_index, x_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm positions of the West/ East limits in the context of the state and its convex hull\n",
    "x_min_coord = Oregon_vertices[0]\n",
    "x_max_coord = Oregon_vertices[137]\n",
    "fig_Oregon_limits = plt.figure()\n",
    "ax = fig_Oregon_limits.add_subplot(111)\n",
    "ax.scatter(x_min_coord[0], x_min_coord[1], c='red', s = 300)\n",
    "ax.scatter(x_max_coord[0], x_max_coord[1], c='red', s = 300)\n",
    "\n",
    "hull = scipy.spatial.ConvexHull(Oregon_vertices)\n",
    "hull_plot = scipy.spatial.convex_hull_plot_2d(hull, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot and assess travel distance for the 2 possible border paths and 2 possible Convex Hull paths:\n",
    "fig_Oregon_paths = plt.figure()\n",
    "fig_Oregon_paths.set_size_inches(10,10)\n",
    "\n",
    "ax_border_1 = fig_Oregon_paths.add_subplot(221)\n",
    "ax_border_1.plot(Oregon_vertices[:138, 0], Oregon_vertices[:138, 1])\n",
    "dist_1 = np.diag(scipy.spatial.distance_matrix(Oregon_vertices[:137],Oregon_vertices[1:138])).sum()\n",
    "ax_border_1.set_title('Border path 1\\n D={dist}'.format(dist=dist_1))\n",
    "\n",
    "ax_border_2 = fig_Oregon_paths.add_subplot(222)\n",
    "cycled_array = np.concatenate((Oregon_vertices,np.array([Oregon_vertices[0,...]])))\n",
    "ax_border_2.plot(cycled_array[137:, 0], cycled_array[137:, 1])\n",
    "dist_2 = np.diag(scipy.spatial.distance_matrix(cycled_array[137:-1],cycled_array[138:])).sum()\n",
    "ax_border_2.set_title('Border path 2\\n D={dist}'.format(dist=dist_2))\n",
    "\n",
    "#note: in 2D scipy returns hull coords in CCW order\n",
    "hull_coords = hull.points[hull.vertices]\n",
    "hull_min_index = np.argmin(hull_coords[...,0])\n",
    "hull_max_index = np.argmax(hull_coords[...,0])\n",
    "ax_border_3 = fig_Oregon_paths.add_subplot(223)\n",
    "ax_border_3.plot(hull_coords[hull_max_index:hull_min_index + 1,0],hull_coords[hull_max_index:hull_min_index + 1,1])\n",
    "dist_3 = np.diag(scipy.spatial.distance_matrix(hull_coords[hull_max_index:hull_min_index],hull_coords[hull_max_index + 1:hull_min_index + 1])).sum()\n",
    "ax_border_3.set_title('Hull path 1\\n D={dist}'.format(dist=dist_3))\n",
    "\n",
    "ax_border_4 = fig_Oregon_paths.add_subplot(224)\n",
    "cycled_hull_coords = np.concatenate((hull_coords,hull_coords))\n",
    "ax_border_4.plot(cycled_hull_coords[hull_min_index:hull_coords.shape[0] + 2,0], cycled_hull_coords[hull_min_index:hull_coords.shape[0] + 2,1])\n",
    "dist_4 = np.diag(scipy.spatial.distance_matrix(cycled_hull_coords[hull_min_index:hull_coords.shape[0] + 1],cycled_hull_coords[hull_min_index + 1:hull_coords.shape[0] + 2])).sum()\n",
    "ax_border_4.set_title('Hull path 2\\n D={dist}'.format(dist=dist_4))\n",
    "\n",
    "for axis in [ax_border_1, ax_border_2, ax_border_3,ax_border_4]:\n",
    "    axis.scatter(x_min_coord[0], x_min_coord[1], c='red', s = 300, alpha = 0.3)\n",
    "    axis.scatter(x_max_coord[0], x_max_coord[1], c='red', s = 300, alpha = 0.3)\n",
    "    axis.set_xlim(-128,-112)\n",
    "    axis.set_ylim(40,48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, clockwise Hull Path 1 is the shortest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Estimate the surface area of a spherical influenza A virus based on my simulation coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and plot the data:\n",
    "fig_flu = plt.figure()\n",
    "fig_flu.set_size_inches(7,7)\n",
    "flu_coords = pickle.load(open('flu_coords.p','rb'))\n",
    "ax = fig_flu.add_subplot(111,projection = '3d')\n",
    "ax.scatter(flu_coords[...,0], flu_coords[...,1], flu_coords[...,2])\n",
    "ax.set_xlabel('x ($\\AA$)')\n",
    "ax.set_ylabel('y ($\\AA$)')\n",
    "ax.set_zlabel('z ($\\AA$)')\n",
    "ax.set_xlim3d(400,1200)\n",
    "ax.set_ylim3d(400,1200)\n",
    "ax.set_zlim3d(0,800)\n",
    "ax.set_title('Flu Envelope Coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the 3D convex hull, plot the facets (triangles) of the hull, and sum together their areas to estimate the overall area of the viral surface\n",
    "fig_flu_hull = plt.figure()\n",
    "ax = fig_flu_hull.add_subplot(111, projection = '3d')\n",
    "flu_hull = scipy.spatial.ConvexHull(flu_coords)\n",
    "hull_triangle_coords = flu_hull.points[flu_hull.simplices]\n",
    "flu_triangles = Poly3DCollection(hull_triangle_coords, alpha = 0.1)\n",
    "ax.add_collection3d(flu_triangles)\n",
    "ax.set_xlabel('x ($\\AA$)')\n",
    "ax.set_ylabel('y ($\\AA$)')\n",
    "ax.set_zlabel('z ($\\AA$)')\n",
    "ax.set_xlim3d(400,1200)\n",
    "ax.set_ylim3d(400,1200)\n",
    "ax.set_zlim3d(0,800)\n",
    "fig_flu_hull.set_size_inches(7,7)\n",
    "ax.set_title('Flu Convex Hull')\n",
    "\n",
    "print hull_triangle_coords.shape\n",
    "print 'surface area estimate from Convex Hull:', flu_hull.area\n",
    "\n",
    "#compare again surface area of roughly equivalent sphere\n",
    "crude_radius = (flu_coords[...,2].max() - flu_coords[...,2].min()) / 2.\n",
    "sphere_SA = 4. * math.pi * (crude_radius ** 2)\n",
    "print 'surface area of roughly equivalent sphere:', sphere_SA\n",
    "print '% reconstitution of sphere:', flu_hull.area / sphere_SA * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that flu isn't a perfect sphere, that % reconstitution of SA is an excellent indication that the calcluation was an excellent estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Triangulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triangulating a point set can be quite different from triangulating a polygon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Definition and Triangle-Splitting Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **triangulation** of a planar point set *S* is a subdivision of the plane determined by a maximal set of noncrossing edges whose vertex set is *S*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Triangle Splitting Algorithm: \n",
    " 1. Find the Convex Hull of S\n",
    " 2. Triangulate the hull as a polygon\n",
    " 3. Choose an interior point and draw edges to the three vertices of the triangle that contains it\n",
    " 4. Repeat step 3 until the interior points are exhausted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demonstration\n",
    "import triangle\n",
    "\n",
    "def triangle_splitting(point_set):\n",
    "    fig_splitting_progress = plt.figure()\n",
    "    fig_splitting_progress.set_size_inches(16,4)\n",
    "    ax_step_1 = fig_splitting_progress.add_subplot(121)\n",
    "    \n",
    "    hull = scipy.spatial.ConvexHull(point_set)\n",
    "    step_1_plot = scipy.spatial.convex_hull_plot_2d(hull, ax_step_1)\n",
    "    \n",
    "    #we assume that the point set is in general position (no 3 points collinear)\n",
    "    hull_coordinates = hull.points[hull.vertices]\n",
    "    segment_start_indices = np.arange(hull_coordinates.shape[0])\n",
    "    segment_end_indices = segment_start_indices + 1\n",
    "    segment_end_indices[-1] = 0\n",
    "    segment_indices = np.array(zip(segment_start_indices, segment_end_indices))\n",
    "    \n",
    "    hull_vertex_dict = dict(vertices = hull_coordinates, segments = segment_indices)\n",
    "    tri = triangle.triangulate(hull_vertex_dict, 'p') #constrained polygon triangulation, as before\n",
    "    \n",
    "    simplex_coords = hull_coordinates[tri['triangles']]\n",
    "    triangles = PolyCollection((simplex_coords), alpha = 0.1)\n",
    "    ax_step_1.add_collection(triangles)\n",
    "    ax_step_1.set_title('Step 1: Convex Hull + Polygon Triangulation')\n",
    "    \n",
    "    #step 2: identify interior points and draw edges to vertices of triangles that contain them (iteratively)\n",
    "    ax_step_2 = fig_splitting_progress.add_subplot(122)\n",
    "    \n",
    "    all_indices = np.arange(point_set.shape[0])\n",
    "    interior_indices = all_indices[np.in1d(all_indices, hull.vertices, invert=True)]\n",
    "    interior_coords = hull.points[interior_indices]\n",
    "    \n",
    "    interior_indices = range(interior_coords.shape[0])\n",
    "    \n",
    "    triangle_index = 0\n",
    "    triangles_left = simplex_coords.shape[0]\n",
    "    while triangles_left > 0:\n",
    "        triangle_coords = simplex_coords[triangle_index]\n",
    "        current_path = matplotlib.path.Path(triangle_coords)\n",
    "        for interior_index in interior_indices:\n",
    "            interior_point = interior_coords[interior_index]\n",
    "            if current_path.contains_point(interior_point):\n",
    "                interior_indices.remove(interior_index)\n",
    "                ax_step_2.plot([interior_point[0],triangle_coords[0][0]],[interior_point[1],triangle_coords[0][1]], c = 'r')\n",
    "                ax_step_2.plot([interior_point[0],triangle_coords[1][0]],[interior_point[1],triangle_coords[1][1]], c = 'r')\n",
    "                ax_step_2.plot([interior_point[0],triangle_coords[2][0]],[interior_point[1],triangle_coords[2][1]], c = 'r')\n",
    "                new_triangle_1 = np.concatenate((triangle_coords[0], triangle_coords[1], interior_point)).reshape(1,3,2)\n",
    "                new_triangle_2 = np.concatenate((triangle_coords[1],triangle_coords[2], interior_point)).reshape(1,3,2)\n",
    "                new_triangle_3 = np.concatenate((triangle_coords[0],triangle_coords[2], interior_point)).reshape(1,3,2)\n",
    "                simplex_coords = np.concatenate((simplex_coords, new_triangle_1, new_triangle_2, new_triangle_3))\n",
    "                triangles_left += 3 \n",
    "                break\n",
    "        triangles_left -= 1\n",
    "        triangle_index += 1\n",
    "                \n",
    "    #updated plot with new triangles from interior points\n",
    "    triangles = PolyCollection((simplex_coords), alpha = 0.1)\n",
    "    ax_step_2.add_collection(triangles)\n",
    "    step_2_plot = scipy.spatial.convex_hull_plot_2d(hull, ax_step_2)\n",
    "    ax_step_2.set_title('Step 2: Iterative Edge Drawing from Interior Points')\n",
    "    \n",
    "random_points = np.random.random_sample((10,2))\n",
    "triangle_splitting(random_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on insights from **Euler**, we know that the number of triangles in a given point set is always fixed as: $2k + h - 2$\n",
    "\n",
    "Where $k$ is a count of internal points and $h$ is a count of hull points and $n = k + h$\n",
    "\n",
    "However, the number of possible triangulations (permutations leading to the same number of triangles) for a given point set is far more difficult to determine, and only recently have mathematicians even been able to place an upper bound on the number of possible triangulations. The upper bound appears to be $30^n$ possible triangulations based on the work of Sharir, Sheffer, and Welzl (2009)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Flip Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**: For a point set $S$, the *flip graph* of $S$ is a graph whose nodes are the set of triangulations of $S$. Two nodes, $T_1$ and $T_2$, of the flip graph are connected if one diagonal of $T_1$ can be flipped to obtain $T_2$. It is effectively the **space of triangulations** of $S$.\n",
    "\n",
    "The flip graph of any point set in the plane is connected (you can convert between different triangulations with edge flipping), which was proven by Charles Lawson in 1971."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example of a Flip Graph from the text book:\n",
    "![Flip_Graph](images/flip_graph.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip graphs have many interesting properties and many triangulation algorithms effectively explore the space of the flip graph to achieve desired results. I'm not aware of any python libraries that generate the flip graphs for a point set in the plane, so that might be an interesting exercise.\n",
    "\n",
    "In 3D it is not known if the flip graph between different tetrahedralizations is connected (or if there may be isolated nodes). Discoveries in this domain may benefit meshing / computer graphics, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Triangulations and Applications\n",
    "\n",
    "\n",
    "Type of Triangulation | 2D Time Complexity | Example Application(s)\n",
    "----------------------|--------------------|------------------------\n",
    "Delaunay | $O(n \\textrm{ log } n)$ | Modelling Terrain (3D maps of Earth)\n",
    "Minimum-weight | NP-hard | Economical Networking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Delaunay Triangulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 Definition and Basic Information\n",
    "\n",
    "Named after Boris Delaunay (Russian Mathematician)\n",
    "\n",
    "A **Delaunay Triangulation** is a triangulation that only has **legal edges**--edges that avoid small angles in triangles. The lexicographically sorted comparison of the full set of angles in two triangulations will always have larger angles for the Delaunay triangulation (other triangulations will have a smaller angle first).\n",
    "\n",
    "General Position for Delaunay in 2D: no four points are cocircular\n",
    "\n",
    "Textbook example of terrain reconstruction sensitivity to triangulation:\n",
    "![terrain_Delaunay](images/terrain_reconstruction.jpg)\n",
    "\n",
    "It is actually possible to construct a 2D Delaunay triangulation starting from any arbitrary triangulation by flipping one edge at a time (progressive illegal to legal edge flips), although this algorithm is slow ($O(n^2)$) and cannot be extended to 3D cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 The Empty Circle Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#none of the original data points in S can fall within the circumcircle of a triangle for a Delaunay triangulation (alternative and very important definition)\n",
    "#demonstration using scipy.spatial once again:\n",
    "fig_Delaunay_circles = plt.figure()\n",
    "fig_Delaunay_circles.set_size_inches(8,8)\n",
    "ax = fig_Delaunay_circles.add_subplot(111, aspect='equal')\n",
    "random_points = np.random.random_sample((10,2))\n",
    "tri = scipy.spatial.Delaunay(random_points)\n",
    "ax.triplot(random_points[...,0], random_points[...,1], tri.simplices, 'go-')\n",
    "\n",
    "#deal with calculating and plotting the circumcircles\n",
    "circumcenters, circumradii = circumcircle.calc_circumcircle(tri.points[tri.simplices])\n",
    "patches = []\n",
    "for circumcenter_coordinates, circumradius in zip(circumcenters,circumradii):\n",
    "    patches.append(matplotlib.patches.Circle((circumcenter_coordinates[0],circumcenter_coordinates[1]),circumradius[0],fill=False, alpha=1.0, fc='none', ec='none',))\n",
    "p = PatchCollection(patches, alpha=0.1,match_original = True)\n",
    "ax.add_collection(p)\n",
    "\n",
    "ax.set_title('Delaunay Empty Circle Property')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that connecting the circumcenters of the circumcircles would produce the Voronoi diagram (they are dual graphs) -- this can be a very useful property and indeed Delaunay was a student of Voronoi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3 Practical Applications of scipy.spatial.Delaunay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problem: You're building a network with prohibitively expensive wiring but as long as there is a path from one computer to another the network will function properly. Given a set of 25 computers (nodes) with fixed positions (i.e., in an office), find the minimum amount of wiring and the appropriate connectivity for the network. The key here is to exploit the fact that the Euclidean minimum spanning tree (EMST) is a subgraph of the Delaunay triangulation of the point set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "computer_positions = np.random.random_sample((25,2))\n",
    "tri = scipy.spatial.Delaunay(computer_positions)\n",
    "#need undirected graph data in a format ready for scipy.sparse.csgraph.minimum_spanning_tree\n",
    "#this will be an NxN symmetric matrix with Euclidean distances for direct connections in the triangulation, and 0 for \"self\" and other points that are not connected\n",
    "\n",
    "#so we effectively want a special distance matrix, which means we need to know which points are connected, so we will likely have to use the simplices attribute of tri\n",
    "\n",
    "triangle_indices = tri.simplices #has shape (n_triangles, 3)\n",
    "\n",
    "#iterate through the triangle indices and populate a template distance matrix (default 0 for no connection)\n",
    "undirected_graph = np.zeros((25,25))\n",
    "\n",
    "for triangle_index_array in triangle_indices:\n",
    "    equivalent_coordinate_array = tri.points[triangle_index_array]\n",
    "    distance_array = scipy.spatial.distance.pdist(equivalent_coordinate_array)\n",
    "    undirected_graph[triangle_index_array[0],triangle_index_array[1]] = distance_array[0]\n",
    "    undirected_graph[triangle_index_array[0],triangle_index_array[2]] = distance_array[1]\n",
    "    undirected_graph[triangle_index_array[1],triangle_index_array[2]] = distance_array[2]\n",
    "\n",
    "#sanity check: no point should be connected to itself (all diagonal values zero)\n",
    "print 'diagonal of undirected_graph:', np.diag(undirected_graph)\n",
    "\n",
    "sparse_result = scipy.sparse.csgraph.minimum_spanning_tree(undirected_graph)\n",
    "\n",
    "#iterate through sparse matrix, plotting and adding up distances\n",
    "fig_emst = plt.figure()\n",
    "fig_emst.set_size_inches(8,8)\n",
    "ax = fig_emst.add_subplot(111,aspect='equal')\n",
    "\n",
    "cx = sparse_result.tocoo() #convert to coordinate representation of matrix\n",
    "label = 0\n",
    "total_distance = 0\n",
    "for i,j,v in itertools.izip(cx.row, cx.col, cx.data):\n",
    "    if v != 0: #there's an edge if nonzero\n",
    "        p1 = computer_positions[i]\n",
    "        p2 = computer_positions[j]\n",
    "        total_distance += v\n",
    "        if not label:\n",
    "            ax.plot([p1[0],p2[0]],[p1[1],p2[1]],c='green',ls='-',marker='o', label = 'EMST', alpha = 0.2, lw =12)\n",
    "            label += 1\n",
    "        else: \n",
    "            ax.plot([p1[0],p2[0]],[p1[1],p2[1]],c='green',ls='-',marker='o', alpha = 0.2, lw = 12)\n",
    "ax.legend()\n",
    "ax.set_title('EMST (D = {dist}) as subgraph of Delaunay Triangulation'.format(dist=total_distance))\n",
    "\n",
    "#overlay the original triangulation for comparison\n",
    "ax.triplot(computer_positions[...,0], computer_positions[...,1], triangle_indices, c = 'k',marker = 'o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4.4.4 Measuring the time complexity of `scipy.spatial.Delaunay()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a similar empirical approach to that used above for benchmarking the convex hull code\n",
    "\n",
    "points_list = [1000,20000,30000,50000,70000,100000,200000,300000,500000,700000,900000,1000000]\n",
    "list_times = []\n",
    "\n",
    "for num_points in points_list:\n",
    "    random_2D_points = np.random.random_sample((num_points,2))\n",
    "    start_time = time.time()\n",
    "    tri = scipy.spatial.Delaunay(random_2D_points)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    list_times.append(elapsed_time)\n",
    "    print 'benchmarked', num_points, 'points in:', elapsed_time, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "popt, pcov = scipy.optimize.curve_fit(linear, points_list, list_times)\n",
    "linear_y_data = linear(np.array(points_list), popt[0], popt[1])\n",
    "popt, pcov = scipy.optimize.curve_fit(loglinear, points_list, list_times)\n",
    "loglinear_y_data = loglinear(np.array(points_list), popt[0], popt[1])\n",
    "popt, pcov = scipy.optimize.curve_fit(quadratic, points_list, list_times)\n",
    "quadratic_y_data = quadratic(np.array(points_list), popt[0], popt[1])\n",
    "\n",
    "fig_bench_Delaunay = plt.figure()\n",
    "ax = fig_bench_Delaunay.add_subplot(111)\n",
    "ax.scatter(points_list, list_times, c='k', label='original data', s = 80)\n",
    "ax.plot(points_list, list_times, c='k', label='original data')\n",
    "\n",
    "ax.plot(points_list, linear_y_data, c = 'blue', lw=7,alpha = 0.3, label = 'linear')\n",
    "ax.plot(points_list, loglinear_y_data, c = 'red', lw=7,alpha = 0.3, label = 'loglinear')\n",
    "ax.plot(points_list, quadratic_y_data, c = 'green', lw=7,alpha = 0.3, label = 'quadratic')\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_title('Crude Time Complexity Assessment\\nFor Qhull 2D Delaunay Triangulation')\n",
    "#ax.set_xlim(-50,1.2e+6)\n",
    "#ax.set_ylim(-0.02,0.20)\n",
    "ax.set_xlabel('# Points',fontsize=16)\n",
    "ax.set_ylabel('Time (s)', fontsize=16)\n",
    "fig_bench_Delaunay.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, `scipy.spatial.Delaunay` appears to have loglinear performance, which is the optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5) Voronoi Diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.1 Definition and Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They were first seriously studied by Georgy Voronoi in 1908, but are also known as Thiessen polygons and Dirichlet tessellations.\n",
    "\n",
    "A Voronoi diagram defines Voronoi regions around each of the points in the original data set. The Voronoi region for a given point represents the portion of space in which all points not in the input data are closer to that point than to any other.\n",
    "\n",
    "From a more practical standpoint, if you imagine a data set with all the grocery stores in your city as input points (generators), each grocery store will have its own Voronoi region, where all homes are closer to that grocery store than to any other. Applications span geography, marketing, network coverage, biology, robot motion planning, etc.\n",
    "\n",
    "Crucially, the Voronoi diagram is the mathematical dual of the Delaunay Triangulation.\n",
    "\n",
    "*All Voronoi regions (i.e., polygons in 2D) are convex.* This can be proven (although I won't do it!).\n",
    "\n",
    "**General position in 2D**: no four generators are cocircular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Overview of Algorithms and their Time Complexities (2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Authors | Year | Citations | Paradigm | Performance\n",
    "--------|------|-----------|----------|------------\n",
    "Shamos and Hoey | 1975 | 1101 | divide-and-conquer | $O(n\\:{\\log}\\:n)$\n",
    "Green and Sibson | 1978 | 861 | incremental | $O(n^2)$\n",
    "Guibas and Stolfi | 1985 | 1506 | quad-edge data structure | $O(n\\:{\\log}\\:n)$\n",
    "Fortune | 1987 | 1402 | sweepline | $O(n\\:{\\log}\\:n)$\n",
    "\n",
    "Loglinear performance is known to be optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Practical Problem Solving with `scipy.spatial.Voronoi()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: Determine which residential locations are closest to a given water pump during the cholera outbreak in London ~150 years ago. This is the classic John Snow example with modern mapping data obtained from Robin Wilson (see below). The sizes of the red points are proportional to the number of fatalities reported at that residential location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data modified from Robin Wilson's (University of Southampton) blog\n",
    "array_pump_coords = pickle.load(open('array_pump_data.p','rb')) \n",
    "array_cholera_data = pickle.load(open('array_cholera_data.p','rb')) \n",
    "\n",
    "#plot\n",
    "figure_voronoi = plt.figure()\n",
    "figure_voronoi.set_size_inches(8,8)\n",
    "ax = figure_voronoi.add_subplot('111', aspect='equal')\n",
    "vor = scipy.spatial.Voronoi(array_pump_coords)\n",
    "voronoi_figure = scipy.spatial.voronoi_plot_2d(vor, ax = ax)\n",
    "ax.scatter(array_cholera_data[...,0], array_cholera_data[...,1], s = array_cholera_data[...,2] * 8, c = 'red', edgecolor='none') #scale scatter point area by number of fatalities\n",
    "ax.scatter(array_pump_coords[...,0], array_pump_coords[...,1], s = 60, c = 'blue', edgecolor='none') #default pump sizes a bit too small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: You're designing an autonomous drone that will fly in an urban location and will have to avoid obstacles that are both stationary (i.e., tall buildings) and dynamic (helicopter traffic, etc.). Demonstrate an approach to determining the safest routes (i.e., farthest from obstacles) for the drone in 3D space. Assume that using a random set of 3D points is a suitable simulation of the kinds of coordinate data the drone will receive in real time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "air_traffic_mess = np.random.random_sample((50,3))\n",
    "#the edges of a 3D Voronoi diagram will be the farthest from the obstacle coordinates\n",
    "vor = scipy.spatial.Voronoi(air_traffic_mess)\n",
    "        \n",
    "fig_drone_3d = plt.figure()\n",
    "fig_drone_3d.set_size_inches(8,8)\n",
    "ax = fig_drone_3d.add_subplot(111, projection = '3d')\n",
    "\n",
    "for ridge_indices in vor.ridge_vertices:\n",
    "    voronoi_ridge_coords = vor.vertices[ridge_indices]\n",
    "    ax.plot(voronoi_ridge_coords[...,0], voronoi_ridge_coords[...,1], voronoi_ridge_coords[...,2], lw=2, c = 'green', alpha = 0.05)\n",
    "    \n",
    "vor_vertex_coords = vor.vertices\n",
    "\n",
    "ax.scatter(air_traffic_mess[...,0], air_traffic_mess[...,1], air_traffic_mess[...,2], c= 'k', label='obstacles', edgecolor='none')\n",
    "ax.scatter(vor_vertex_coords[...,0], vor_vertex_coords[...,1], vor_vertex_coords[...,2], c= 'orange', label='Voronoi vertices',edgecolors='white', marker = 'o', alpha = 0.9)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim3d(air_traffic_mess[...,0].min(), air_traffic_mess[...,0].max())\n",
    "ax.set_ylim3d(air_traffic_mess[...,1].min(), air_traffic_mess[...,1].max())\n",
    "ax.set_zlim3d(air_traffic_mess[...,2].min(), air_traffic_mess[...,2].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would want the drone to follow the green lines, although the data still needs to be cleaned up a bit. For example, we'd like to deal with the \"edges at infinity\" (outside the Voronoi diagram, usually denoted as \"-1\" in the data structures returned by scipy/ qhull) more gracefully.\n",
    "\n",
    "At the moment it appears to be non-trivial to plot the polyhedra around each of the obstacles. This is probably because the points need to be in the correct order for each polyhedron and again because of the edges at infinity. \n",
    "\n",
    "A nice take-home exercise would be to attempt to clean this data up and produce a really nice 3D Voronoi diagram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Measuring the Time Complexity for 2D `scipy.spatial.Voronoi()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a similar empirical approach to that used above for benchmarking the convex hull code\n",
    "\n",
    "points_list = [1000,20000,30000,50000,70000,100000,200000,300000,500000,700000,900000,1000000]\n",
    "list_times = []\n",
    "\n",
    "for num_points in points_list:\n",
    "    random_2D_points = np.random.random_sample((num_points,2))\n",
    "    start_time = time.time()\n",
    "    tri = scipy.spatial.Voronoi(random_2D_points)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    list_times.append(elapsed_time)\n",
    "    print 'benchmarked', num_points, 'points in:', elapsed_time, ' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = scipy.optimize.curve_fit(linear, points_list, list_times)\n",
    "linear_y_data = linear(np.array(points_list), popt[0], popt[1])\n",
    "popt, pcov = scipy.optimize.curve_fit(loglinear, points_list, list_times)\n",
    "loglinear_y_data = loglinear(np.array(points_list), popt[0], popt[1])\n",
    "popt, pcov = scipy.optimize.curve_fit(quadratic, points_list, list_times)\n",
    "quadratic_y_data = quadratic(np.array(points_list), popt[0], popt[1])\n",
    "\n",
    "fig_bench_Voronoi = plt.figure()\n",
    "ax = fig_bench_Voronoi.add_subplot(111)\n",
    "ax.scatter(points_list, list_times, c='k', label='original data', s = 80)\n",
    "ax.plot(points_list, list_times, c='k', label='original data')\n",
    "\n",
    "ax.plot(points_list, linear_y_data, c = 'blue', lw=7,alpha = 0.3, label = 'linear')\n",
    "ax.plot(points_list, loglinear_y_data, c = 'red', lw=7,alpha = 0.3, label = 'loglinear')\n",
    "ax.plot(points_list, quadratic_y_data, c = 'green', lw=7,alpha = 0.3, label = 'quadratic')\n",
    "ax.legend(loc=2)\n",
    "\n",
    "ax.set_title('Crude Time Complexity Assessment\\nFor Qhull 2D Voronoi Diagram')\n",
    "#ax.set_xlim(-50,1.2e+6)\n",
    "#ax.set_ylim(-0.02,0.20)\n",
    "ax.set_xlabel('# Points',fontsize=16)\n",
    "ax.set_ylabel('Time (s)', fontsize=16)\n",
    "fig_bench_Voronoi.set_size_inches(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loglinear performance is known to be optimal so we can't really improve on this from an algorithmic standpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) How can we improve the Python computational geometry tool set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Some of my Efforts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 `scipy.spatial.SphericalVoronoi()` [upcoming scipy 0.18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nikolai Nowaczyk and I worked on this PR (https://github.com/scipy/scipy/pull/5232) for quite some time but it was eventually merged in and should be available in scipy 0.18, which probably won't be out for quite some time. You could, however, compile scipy from the master branch to use it if you need it.\n",
    "\n",
    "Specific applications include my work on spherical viruses, geography, astrophysics, MRI analysis, and any other field that deals with roughly spherical objects. A concise example follows below. **Note that this algorithm has quadratic time complexity, but loglinear is optimal**--so this is an opportunity for improvement within the Python community. That said, many of the better-performing algorithms appear challenging to implement (I tried one of them for a few months without much luck)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple example for usage of scipy.spatial.SphericalVoronoi using random points on the surface of a sphere (but could easily imagine these points representing i.e., airports or cities on the surface of the earth, etc.)\n",
    "\n",
    "num_points = 600\n",
    "\n",
    "def marsaglia(num_points):\n",
    "    '''generate random points on surface of sphere using Marsaglia's method (see: http://mathworld.wolfram.com/SpherePointPicking.html)'''\n",
    "    x1 = np.random.uniform(low=-1.0, high=1.0,size=num_points)\n",
    "    x2 = np.random.uniform(low=-1.0, high=1.0,size=num_points)\n",
    "\n",
    "    #filter out points for which the sum of squares between the two distribution is >= 1\n",
    "    mask = np.where(x1 ** 2 + x2 ** 2 < 1)\n",
    "    x1 = x1[mask]\n",
    "    x2 = x2[mask]\n",
    "\n",
    "    x_coords = 2 * x1 * np.sqrt(1 - x1 ** 2 - x2 ** 2)\n",
    "    y_coords = 2 * x2 * np.sqrt(1 - x1 ** 2 - x2 ** 2)\n",
    "    z_coords = 1 - 2 * (x1 ** 2 + x2 ** 2)\n",
    "    return np.stack((x_coords,y_coords,z_coords), axis=-1) \n",
    "\n",
    "points = marsaglia(num_points=num_points)\n",
    "\n",
    "fig_spherical_Voronoi = plt.figure()\n",
    "fig_spherical_Voronoi.set_size_inches(16,8)\n",
    "ax1 = fig_spherical_Voronoi.add_subplot(121, projection = '3d')\n",
    "ax1.scatter(points[...,0], points[...,1], points[...,2],c='blue')\n",
    "ax1.set_title('Random Points on Sphere')\n",
    "\n",
    "ax2 = fig_spherical_Voronoi.add_subplot(122, projection = '3d')\n",
    "#calculate the Voronoi diagram on the surface of the sphere and plot the Voronoi region polygons\n",
    "sv = scipy.spatial.SphericalVoronoi(points, radius=1)\n",
    "sv.sort_vertices_of_regions() #generally needed for plotting / SA calculation\n",
    "\n",
    "for region in sv.regions:\n",
    "    random_color = colors.rgb2hex(np.random.rand(3))\n",
    "    polygon = Poly3DCollection([sv.vertices[region]], alpha=1.0)\n",
    "    polygon.set_color(random_color)\n",
    "    ax2.add_collection3d(polygon)\n",
    "    \n",
    "ax2.set_title('Voronoi Regions')\n",
    "\n",
    "for axis in [ax1,ax2]:\n",
    "    axis.set_xlim(-1.5,1.5)\n",
    "    axis.set_ylim(-1.5,1.5)\n",
    "    axis.set_zlim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2 Calculating Surface Area of Spherical Polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only have I had to perform this calculation extensively in my own work on viruses, but I frequently get emails from geographers and MRI scientists asking about this calculation for polygons on the surface of a sphere. I recently wrote a proposal (https://github.com/scipy/scipy/issues/6069) to incorporate calculations of this nature into scipy. The best code I have for doing this at the moment was improved by Edd Edmondson (University of Portsmouth). Let's see if we get a sensible result from the sum of the surface areas of all polygons in the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draft of code to calculate spherical polygon surface area\n",
    "def convert_cartesian_array_to_spherical_array(coord_array,angle_measure='radians'):\n",
    "    '''Take shape (N,3) cartesian coord_array and return an array of the same shape in spherical polar form (r, theta, phi). Based on StackOverflow response: http://stackoverflow.com/a/4116899\n",
    "    use radians for the angles by default, degrees if angle_measure == 'degrees' '''\n",
    "    spherical_coord_array = np.zeros(coord_array.shape)\n",
    "    xy = coord_array[...,0]**2 + coord_array[...,1]**2\n",
    "    spherical_coord_array[...,0] = np.sqrt(xy + coord_array[...,2]**2)\n",
    "    spherical_coord_array[...,1] = np.arctan2(coord_array[...,1], coord_array[...,0])\n",
    "    spherical_coord_array[...,2] = np.arccos(coord_array[...,2] / spherical_coord_array[...,0])\n",
    "    if angle_measure == 'degrees':\n",
    "        spherical_coord_array[...,1] = np.degrees(spherical_coord_array[...,1])\n",
    "        spherical_coord_array[...,2] = np.degrees(spherical_coord_array[...,2])\n",
    "    return spherical_coord_array\n",
    "\n",
    "def convert_spherical_array_to_cartesian_array(spherical_coord_array,angle_measure='radians'):\n",
    "    '''Take shape (N,3) spherical_coord_array (r,theta,phi) and return an array of the same shape in cartesian coordinate form (x,y,z). Based on the equations provided at: http://en.wikipedia.org/wiki/List_of_common_coordinate_transformations#From_spherical_coordinates\n",
    "    use radians for the angles by default, degrees if angle_measure == 'degrees' '''\n",
    "    cartesian_coord_array = np.zeros(spherical_coord_array.shape)\n",
    "    #convert to radians if degrees are used in input (prior to Cartesian conversion process)\n",
    "    if angle_measure == 'degrees':\n",
    "        spherical_coord_array[...,1] = np.deg2rad(spherical_coord_array[...,1])\n",
    "        spherical_coord_array[...,2] = np.deg2rad(spherical_coord_array[...,2])\n",
    "    #now the conversion to Cartesian coords\n",
    "    cartesian_coord_array[...,0] = spherical_coord_array[...,0] * np.cos(spherical_coord_array[...,1]) * np.sin(spherical_coord_array[...,2])\n",
    "    cartesian_coord_array[...,1] = spherical_coord_array[...,0] * np.sin(spherical_coord_array[...,1]) * np.sin(spherical_coord_array[...,2])\n",
    "    cartesian_coord_array[...,2] = spherical_coord_array[...,0] * np.cos(spherical_coord_array[...,2])\n",
    "    return cartesian_coord_array\n",
    "\n",
    "def calculate_haversine_distance_between_spherical_points(cartesian_array_1,cartesian_array_2,sphere_radius):\n",
    "    '''Calculate the haversine-based distance between two points on the surface of a sphere. Should be more accurate than the arc cosine strategy. See, for example: http://en.wikipedia.org/wiki/Haversine_formula'''\n",
    "    spherical_array_1 = convert_cartesian_array_to_spherical_array(cartesian_array_1)\n",
    "    spherical_array_2 = convert_cartesian_array_to_spherical_array(cartesian_array_2)\n",
    "    lambda_1 = spherical_array_1[1]\n",
    "    lambda_2 = spherical_array_2[1]\n",
    "    phi_1 = spherical_array_1[2]\n",
    "    phi_2 = spherical_array_2[2]\n",
    "    #we rewrite the standard Haversine slightly as long/lat is not the same as spherical coordinates - phi differs by pi/4\n",
    "    spherical_distance = 2.0 * sphere_radius * math.asin(math.sqrt( ((1 - math.cos(phi_2-phi_1))/2.) + math.sin(phi_1) * math.sin(phi_2) * ( (1 - math.cos(lambda_2-lambda_1))/2.)  ))\n",
    "    return spherical_distance\n",
    "\n",
    "def calculate_surface_area_of_a_spherical_Voronoi_polygon(array_ordered_Voronoi_polygon_vertices,sphere_radius):\n",
    "    '''Calculate the surface area of a polygon on the surface of a sphere. Based on equation provided here: http://mathworld.wolfram.com/LHuiliersTheorem.html\n",
    "    Decompose into triangles, calculate excess for each'''\n",
    "    #have to convert to unit sphere before applying the formula\n",
    "    spherical_coordinates = convert_cartesian_array_to_spherical_array(array_ordered_Voronoi_polygon_vertices)\n",
    "    spherical_coordinates[...,0] = 1.0\n",
    "    array_ordered_Voronoi_polygon_vertices = convert_spherical_array_to_cartesian_array(spherical_coordinates)\n",
    "    n = array_ordered_Voronoi_polygon_vertices.shape[0]\n",
    "    #point we start from\n",
    "    root_point = array_ordered_Voronoi_polygon_vertices[0]\n",
    "    totalexcess = 0\n",
    "    #loop from 1 to n-2, with point 2 to n-1 as other vertex of triangle\n",
    "    # this could definitely be written more nicely\n",
    "    b_point = array_ordered_Voronoi_polygon_vertices[1]\n",
    "    root_b_dist = calculate_haversine_distance_between_spherical_points(root_point, b_point, 1.0)\n",
    "    for i in 1 + np.arange(n - 2):\n",
    "        a_point = b_point\n",
    "        b_point = array_ordered_Voronoi_polygon_vertices[i+1]\n",
    "        root_a_dist = root_b_dist\n",
    "        root_b_dist = calculate_haversine_distance_between_spherical_points(root_point, b_point, 1.0)\n",
    "        a_b_dist = calculate_haversine_distance_between_spherical_points(a_point, b_point, 1.0)\n",
    "        s = (root_a_dist + root_b_dist + a_b_dist) / 2.\n",
    "        totalexcess += 4 * math.atan(math.sqrt( math.tan(0.5 * s) * math.tan(0.5 * (s-root_a_dist)) * math.tan(0.5 * (s-root_b_dist)) * math.tan(0.5 * (s-a_b_dist))))\n",
    "    return totalexcess * (sphere_radius ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum the polygon areas from above and compare with theoretical surface area of unit sphere\n",
    "calculated_SA = 0\n",
    "for region in sv.regions:\n",
    "    SA = calculate_surface_area_of_a_spherical_Voronoi_polygon(sv.vertices[region], 1.0)\n",
    "    calculated_SA += SA\n",
    "    \n",
    "print 'calculated_SA:', calculated_SA\n",
    "print 'theoretical SA:', 4 * math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that certainly looks like a sensible result! However, as you would be able to see in the above proposal, there are probably a few mysteries left to solve (if only to determine the range of pathological inputs). Also, what if we wanted to avoid a python for loop? Can we vectorize this code in numpy ufunc style if each polygon can have a different shape? Usually ufuncs operate on 'rectangular' arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Other Opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  6.2.1 Improve Matplotlib Handling of Spherical Polygons\n",
    "\n",
    "Nikolai Nowaczyk is working on this. I'm sure additional help could be useful!\n",
    "\n",
    "See matplotlib [Issue 5294](https://github.com/matplotlib/matplotlib/issues/5294) and [PR 6248](https://github.com/matplotlib/matplotlib/pull/6248)\n",
    "\n",
    "Consider the case of plotting the spherical Voronoi result for a much smaller set of generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = marsaglia(num_points=25)\n",
    "sv = scipy.spatial.SphericalVoronoi(points,radius = 1)\n",
    "sv.sort_vertices_of_regions()\n",
    "\n",
    "fig_problematic_polygons = plt.figure()\n",
    "ax = fig_problematic_polygons.add_subplot(111, projection = '3d')\n",
    "\n",
    "for region in sv.regions:\n",
    "    random_color = colors.rgb2hex(np.random.rand(3))\n",
    "    polygon = Poly3DCollection([sv.vertices[region]], alpha=1.0)\n",
    "    polygon.set_color(random_color)\n",
    "    ax.add_collection3d(polygon)\n",
    "\n",
    "ax.set_xlim(-1.5,1.5)\n",
    "ax.set_ylim(-1.5,1.5)\n",
    "ax.set_zlim(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2 Working with imperfect spheres (like our planet), cylinders and other shapes? Your ideas?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
